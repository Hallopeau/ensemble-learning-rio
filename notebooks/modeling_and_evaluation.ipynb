{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a96f3-0f4d-4c16-87c6-9269f1e9d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1b026-952f-4940-8b90-e0faace18f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Load grid data\n",
    "grid = gpd.read_file(\"/path/to/your/data/data.gpkg\")\n",
    "\n",
    "# Assign binary labels based on conditions\n",
    "grid[\"label\"] = np.where(\n",
    "    (grid[\"vegetation\"] <= 0.95)\n",
    "    & (grid[\"ghsl\"] >= 0.5)\n",
    "    & (grid[\"osm\"] <= 0.5)\n",
    "    & (grid[\"favelas\"] > 0.9),\n",
    "    1,\n",
    "    np.where(\n",
    "        (grid[\"vegetation\"] <= 0.95)\n",
    "        & (grid[\"ghsl\"] >= 0.5)\n",
    "        & (grid[\"osm\"] <= 0.5)\n",
    "        & (grid[\"favelas\"] == 0),\n",
    "        0,\n",
    "        np.nan,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Keep only labeled data\n",
    "dataset = grid[grid[\"label\"].notna()]\n",
    "\n",
    "# Load zones shapefile\n",
    "zones = gpd.read_file(\"/path/to/your/data/zones.shp\")\n",
    "\n",
    "# Assign each cell to a zone based on centroid position\n",
    "dataset[\"centroid\"] = dataset.geometry.centroid\n",
    "points_zones = gpd.sjoin(\n",
    "    dataset.set_geometry(\"centroid\"),\n",
    "    zones[[\"fid\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "dataset[\"zone\"] = points_zones[\"fid\"]\n",
    "dataset = dataset.drop(columns=[\"centroid\"])\n",
    "dataset = dataset[dataset[\"zone\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda2556-1cd7-4c15-8d30-5c6b25cc75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot feature importances and correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5606d4-87fb-439b-8111-c2f9dd57bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Font configuration\n",
    "font_path = \"/usr/share/fonts/truetype/cmu/cmunrm.ttf\"\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "font_prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams[\"font.family\"] = font_prop.get_name()\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    \"vegetation\", \"slope\", \"profile_co\", \"entropy\",\n",
    "    \"nodes\", \"roads\", \"mean_conne\", \"min_connex\", \"max_connex\"\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X = np.array(dataset[feature_cols].apply(lambda row: row.tolist(), axis=1).to_list())\n",
    "y = np.array(dataset[\"label\"].to_list())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Vertical bar plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.bar(range(len(importances)), importances, align=\"center\", color=\"steelblue\")\n",
    "plt.xticks(\n",
    "    range(len(importances)),\n",
    "    [\n",
    "        \"Vegetation\", \"Slope\", \"Profile convexity\", \"Entropy\",\n",
    "        \"OSM nodes\", \"OSM roads\", \"Mean connectivity\",\n",
    "        \"Minimum connectivity\", \"Maximum connectivity\"\n",
    "    ],\n",
    "    rotation=90,\n",
    "    fontsize=11\n",
    ")\n",
    "plt.yticks(fontsize=11)\n",
    "plt.ylabel(\"Feature Importance\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = np.corrcoef(X, rowvar=False)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.imshow(correlation_matrix, cmap=\"Reds\", interpolation=\"none\")\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "\n",
    "plt.xticks(\n",
    "    range(len(feature_cols)),\n",
    "    [\n",
    "        \"Vegetation\", \"Slope\", \"Profile convexity\", \"Entropy\",\n",
    "        \"OSM nodes\", \"OSM roads\", \"Mean connectivity\",\n",
    "        \"Minimum connectivity\", \"Maximum connectivity\"\n",
    "    ],\n",
    "    rotation=90,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.yticks(\n",
    "    range(len(feature_cols)),\n",
    "    [\n",
    "        \"Vegetation\", \"Slope\", \"Profile convexity\", \"Entropy\",\n",
    "        \"OSM nodes\", \"OSM roads\", \"Mean connectivity\",\n",
    "        \"Minimum connectivity\", \"Maximum connectivity\"\n",
    "    ],\n",
    "    fontsize=10\n",
    ")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Horizontal bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.barh(range(len(importances)), importances, align=\"center\", color=\"steelblue\")\n",
    "plt.yticks(\n",
    "    range(len(importances)),\n",
    "    [\n",
    "        \"Vegetation\", \"Slope\", \"Profile convexity\", \"Entropy\",\n",
    "        \"Total street intersections\", \"Total street length\",\n",
    "        \"Mean connectivity\", \"Minimum connectivity\", \"Maximum connectivity\"\n",
    "    ],\n",
    "    fontsize=11\n",
    ")\n",
    "plt.xticks(fontsize=11)\n",
    "plt.xlabel(\"Feature Importance\", fontsize=12)\n",
    "plt.ylabel(\"Features\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances_horizontal.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2409879-f5c1-41f3-a406-9624a079cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff92fc4-4bc7-40fb-9af6-0e6c678839ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Feature columns used for training\n",
    "f_cols = [\n",
    "    \"vegetation\", \"slope\", \"profile_co\", \"entropy\",\n",
    "    \"nodes\", \"roads\", \"mean_conne\", \"min_connex\", \"max_connex\"\n",
    "]\n",
    "\n",
    "# Extract features and labels\n",
    "features = np.array(dataset[f_cols].values)\n",
    "labels = np.array(dataset[\"label\"].values)\n",
    "\n",
    "# Separate by class\n",
    "class_0 = features[labels == 0]\n",
    "class_1 = features[labels == 1]\n",
    "\n",
    "# Balance dataset by downsampling the majority class\n",
    "if len(class_0) > len(class_1):\n",
    "    class_0_downsampled = resample(\n",
    "        class_0, replace=False, n_samples=len(class_1), random_state=42\n",
    "    )\n",
    "    features_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "    labels_balanced = np.hstack([\n",
    "        np.zeros(len(class_0_downsampled)),\n",
    "        np.ones(len(class_1))\n",
    "    ])\n",
    "else:\n",
    "    class_1_downsampled = resample(\n",
    "        class_1, replace=False, n_samples=len(class_0), random_state=42\n",
    "    )\n",
    "    features_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "    labels_balanced = np.hstack([\n",
    "        np.zeros(len(class_0)),\n",
    "        np.ones(len(class_1_downsampled))\n",
    "    ])\n",
    "\n",
    "# Shuffle data to remove ordering bias\n",
    "shuffle_idx = np.random.permutation(len(labels_balanced))\n",
    "features_balanced = features_balanced[shuffle_idx]\n",
    "labels_balanced = labels_balanced[shuffle_idx]\n",
    "\n",
    "# Initialize classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = {\n",
    "    \"f1\": \"f1\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\"\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_validate(model, features_balanced, labels_balanced, cv=5, scoring=scoring)\n",
    "\n",
    "# Display results\n",
    "print(f\"Precision: {np.mean(scores['test_precision']):.2f} ± {np.std(scores['test_precision']):.2f}\")\n",
    "print(f\"Recall:    {np.mean(scores['test_recall']):.2f} ± {np.std(scores['test_recall']):.2f}\")\n",
    "print(f\"F1-score:  {np.mean(scores['test_f1']):.2f} ± {np.std(scores['test_f1']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9aa20-b062-41ad-ae06-8d65c5a708f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b1f80-e5f6-48d7-a35f-82cb3aa8c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Get the list of unique zones and reverse order\n",
    "zones = dataset[\"zone\"].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "# Feature columns\n",
    "f_cols = [\n",
    "    \"vegetation\", \"slope\", \"profile_co\", \"entropy\",\n",
    "    \"nodes\", \"roads\", \"mean_conne\", \"min_connex\", \"max_connex\"\n",
    "]\n",
    "\n",
    "folds = []\n",
    "\n",
    "# Perform stratified sampling for each zone\n",
    "for zone_id in zones:\n",
    "    dataset_zone = dataset[dataset[\"zone\"] == zone_id]\n",
    "    X, y = dataset_zone[f_cols].values, dataset_zone[\"label\"].values\n",
    "\n",
    "    class_0 = X[y == 0]\n",
    "    class_1 = X[y == 1]\n",
    "\n",
    "    # Balance classes by downsampling\n",
    "    if len(class_0) > len(class_1):\n",
    "        class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "        X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "        y_balanced = np.hstack([\n",
    "            np.zeros(len(class_0_downsampled)),\n",
    "            np.ones(len(class_1))\n",
    "        ])\n",
    "    else:\n",
    "        class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "        X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "        y_balanced = np.hstack([\n",
    "            np.zeros(len(class_0)),\n",
    "            np.ones(len(class_1_downsampled))\n",
    "        ])\n",
    "\n",
    "    # Shuffle to remove order bias\n",
    "    p = np.random.permutation(len(y_balanced))\n",
    "    X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "\n",
    "    folds.append([X_balanced, y_balanced])\n",
    "\n",
    "# Initialize metric lists\n",
    "f1_scores, precision_scores, recall_scores = [], [], []\n",
    "\n",
    "# Cross-validation by leave-one-zone-out\n",
    "for i in range(len(folds)):\n",
    "    X_test, y_test = folds[i]\n",
    "    X_train = np.vstack([fold[0] for j, fold in enumerate(folds) if j != i])\n",
    "    y_train = np.hstack([fold[1] for j, fold in enumerate(folds) if j != i])\n",
    "\n",
    "    # Train classifier\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Zone {i + 1}: Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")\n",
    "\n",
    "# Global performance summary\n",
    "print(\"\\nOverall performance:\")\n",
    "print(f\"Precision: {np.mean(precision_scores):.2f} ± {np.std(precision_scores):.2f}\")\n",
    "print(f\"Recall:    {np.mean(recall_scores):.2f} ± {np.std(recall_scores):.2f}\")\n",
    "print(f\"F1-score:  {np.mean(f1_scores):.2f} ± {np.std(f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a79273-da86-4f66-b9e9-d1e53c526bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple spatial cross-validations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0b356-ed5e-4732-a61b-cf72d4abae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "# Get the list of unique zones and reverse the order\n",
    "zones = dataset[\"zone\"].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "# Feature columns\n",
    "f_cols = [\n",
    "    \"vegetation\", \"slope\", \"profile_co\", \"entropy\", \n",
    "    \"nodes\", \"roads\", \"mean_conne\", \"min_connex\", \"max_connex\"\n",
    "] \n",
    "\n",
    "# Initialize lists to store evaluation metrics for each zone\n",
    "f1_scores = [[] for _ in range(len(zones))]\n",
    "precision_scores = [[] for _ in range(len(zones))]\n",
    "recall_scores = [[] for _ in range(len(zones))]\n",
    "kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "# Perform 10 rounds of cross-validation\n",
    "for _ in range(10):\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    for z in zones:\n",
    "        dataset_zone = dataset[dataset[\"zone\"] == z]\n",
    "        X, y = dataset_zone[f_cols].values, dataset_zone[\"label\"].values\n",
    "        \n",
    "        class_0 = X[y == 0]\n",
    "        class_1 = X[y == 1]\n",
    "        \n",
    "        # Balance classes using downsampling\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "            X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "            X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "            \n",
    "        # Shuffle the data to avoid order bias\n",
    "        p = np.random.permutation(len(y_balanced))\n",
    "        X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "        \n",
    "        folds.append([X_balanced, y_balanced])\n",
    "\n",
    "    # Train and test the model for each fold\n",
    "    for i in range(len(folds)):\n",
    "        X_test, y_test = folds[i][0], folds[i][1]\n",
    "        \n",
    "        # Use all other folds as training data\n",
    "        X_train = np.vstack([fold[0] for j, fold in enumerate(folds) if j != i])\n",
    "        y_train = np.hstack([fold[1] for j, fold in enumerate(folds) if j != i])\n",
    "        \n",
    "        # Train the classifier\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        precision_scores[i].append(precision_score(y_test, y_pred))\n",
    "        recall_scores[i].append(recall_score(y_test, y_pred))\n",
    "        f1_scores[i].append(f1_score(y_test, y_pred))\n",
    "        kappa_scores[i].append(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "# Display performance metrics for each zone\n",
    "for i in range(len(zones)):\n",
    "    print(f\"Zone {i+1} - Precision: {np.mean(precision_scores[i]):.2f} ± {np.std(precision_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} - Recall: {np.mean(recall_scores[i]):.2f} ± {np.std(recall_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} - F1-score: {np.mean(f1_scores[i]):.2f} ± {np.std(f1_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} - Kappa: {np.mean(kappa_scores[i]):.2f} ± {np.std(kappa_scores[i]):.2f}\\n\")\n",
    "\n",
    "# Compute overall performance metrics\n",
    "print(f\"Overall Precision: {np.mean([np.mean(f) for f in precision_scores]):.2f} ± {np.std([np.mean(f) for f in precision_scores]):.2f}\")\n",
    "print(f\"Overall Recall: {np.mean([np.mean(f) for f in recall_scores]):.2f} ± {np.std([np.mean(f) for f in recall_scores]):.2f}\")\n",
    "print(f\"Overall F1-score: {np.mean([np.mean(f) for f in f1_scores]):.2f} ± {np.std([np.mean(f) for f in f1_scores]):.2f}\")\n",
    "print(f\"Overall Kappa: {np.mean([np.mean(f) for f in kappa_scores]):.2f} ± {np.std([np.mean(f) for f in kappa_scores]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8a1d4-4663-4afe-80b3-dd8c35efb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensemble approach with spatial cross-validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18798454-a3b1-4152-b08b-1109c4616e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the unique zones and reverse the order\n",
    "zones = dataset['zone'].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "# Initialize lists to store scores\n",
    "f1_scores = [[] for _ in range(len(zones))]\n",
    "precision_scores = [[] for _ in range(len(zones))]\n",
    "recall_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "# Store predictions for ensemble evaluation\n",
    "preds = []\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    'vegetation', 'slope', 'profile_co', 'entropy', 'nodes',\n",
    "    'roads', 'mean_conne', 'min_connex', 'max_connex'\n",
    "]\n",
    "\n",
    "# Iterate over each zone for spatial cross-validation\n",
    "for test_zone in zones:\n",
    "    \n",
    "    # Split dataset into training and testing based on zones\n",
    "    train_dataset = dataset[dataset['zone'] != test_zone]\n",
    "    test_dataset = dataset[dataset['zone'] == test_zone]\n",
    "\n",
    "    X_train, y_train = train_dataset[feature_cols].values, train_dataset['label'].values\n",
    "    X_test, y_test = test_dataset[feature_cols].values, test_dataset['label'].values\n",
    "    test_ids = test_dataset['id'].values\n",
    "\n",
    "    # Identify the two classes in the test set\n",
    "    class_0 = X_test[y_test == 0]\n",
    "    class_1 = X_test[y_test == 1]\n",
    "\n",
    "    ids_class_0 = test_ids[y_test == 0]\n",
    "    ids_class_1 = test_ids[y_test == 1]\n",
    "\n",
    "    # Balance the test dataset through downsampling\n",
    "    if len(class_0) > len(class_1):\n",
    "        X_class_0_downsampled, ids_class_0_downsampled = resample(\n",
    "            class_0, ids_class_0, replace=False, n_samples=len(class_1)\n",
    "        )\n",
    "        X_test_balanced = np.vstack([X_class_0_downsampled, class_1])\n",
    "        y_test_balanced = np.hstack([np.zeros(len(X_class_0_downsampled)), np.ones(len(class_1))])\n",
    "        ids_test_balanced = np.hstack([ids_class_0_downsampled, ids_class_1])\n",
    "    else:\n",
    "        X_class_1_downsampled, ids_class_1_downsampled = resample(\n",
    "            class_1, ids_class_1, replace=False, n_samples=len(class_0)\n",
    "        )\n",
    "        X_test_balanced = np.vstack([class_0, X_class_1_downsampled])\n",
    "        y_test_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(X_class_1_downsampled))])\n",
    "        ids_test_balanced = np.hstack([ids_class_0, ids_class_1_downsampled])\n",
    "\n",
    "    # Shuffle the test dataset\n",
    "    p = np.random.permutation(len(y_test_balanced))\n",
    "    X_test_balanced, y_test_balanced, ids_test_balanced = X_test_balanced[p], y_test_balanced[p], ids_test_balanced[p]\n",
    "    \n",
    "    # Store test IDs alongside actual labels\n",
    "    ids_test_balanced = np.column_stack((ids_test_balanced, y_test_balanced))\n",
    "\n",
    "    # Train 100 models for the ensemble approach\n",
    "    for _ in tqdm(range(100), desc=f\"Zone {int(test_zone)}\"):\n",
    "        \n",
    "        # Balance the training dataset\n",
    "        class_0 = X_train[y_train == 0]\n",
    "        class_1 = X_train[y_train == 1]\n",
    "\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "            X_train_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_train_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "            X_train_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_train_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "\n",
    "        # Shuffle the training dataset\n",
    "        p = np.random.permutation(len(y_train_balanced))\n",
    "        X_train_balanced, y_train_balanced = X_train_balanced[p], y_train_balanced[p]\n",
    "\n",
    "        # Train the model\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "        # Predict on the balanced test set\n",
    "        y_pred = model.predict(X_test_balanced)\n",
    "\n",
    "        # Store predictions for ensemble evaluation\n",
    "        ids_test_balanced = np.column_stack((ids_test_balanced, y_pred))\n",
    "\n",
    "        # Compute and store evaluation metrics\n",
    "        f1_scores[int(test_zone - 1)].append(f1_score(y_test_balanced, y_pred))\n",
    "        precision_scores[int(test_zone - 1)].append(precision_score(y_test_balanced, y_pred))\n",
    "        recall_scores[int(test_zone - 1)].append(recall_score(y_test_balanced, y_pred))\n",
    "\n",
    "    preds.append(ids_test_balanced)\n",
    "\n",
    "    # Print per-zone results\n",
    "    print(f\"Average Precision (Zone {int(test_zone)}): {np.mean(precision_scores[int(test_zone - 1)]):.2f} +/- {np.std(precision_scores[int(test_zone - 1)]):.2f}\")\n",
    "    print(f\"Average Recall (Zone {int(test_zone)}): {np.mean(recall_scores[int(test_zone - 1)]):.2f} +/- {np.std(recall_scores[int(test_zone - 1)]):.2f}\")\n",
    "    print(f\"Average F1-score (Zone {int(test_zone)}): {np.mean(f1_scores[int(test_zone - 1)]):.2f} +/- {np.std(f1_scores[int(test_zone - 1)]):.2f}\\n\")\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Precision: {np.mean([np.mean(f) for f in precision_scores]):.2f} +/- {np.std([np.mean(f) for f in precision_scores]):.2f}\")\n",
    "print(f\"Recall: {np.mean([np.mean(f) for f in recall_scores]):.2f} +/- {np.std([np.mean(f) for f in recall_scores]):.2f}\")\n",
    "print(f\"F1-score: {np.mean([np.mean(f) for f in f1_scores]):.2f} +/- {np.std([np.mean(f) for f in f1_scores]):.2f}\\n\")\n",
    "\n",
    "print(\"----- Final Ensemble Evaluation -----\\n\")\n",
    "\n",
    "# Ensemble evaluation\n",
    "ens_recall_scores = []\n",
    "ens_precision_scores = []\n",
    "ens_f1_scores = []\n",
    "\n",
    "for i in zones:\n",
    "    i = int(i - 1)\n",
    "    ids_i = preds[i][:, 0]\n",
    "    labels_i = preds[i][:, 1]\n",
    "    preds_i = preds[i][:, 2:]\n",
    "\n",
    "    # Use majority voting (if the average prediction is ≥ 0.5, classify as 1)\n",
    "    final_preds_i = np.array([1 if np.mean(l) >= 0.5 else 0 for l in preds_i])\n",
    "\n",
    "    # Compute final ensemble metrics\n",
    "    ens_precision_scores.append(precision_score(labels_i, final_preds_i))\n",
    "    ens_recall_scores.append(recall_score(labels_i, final_preds_i))\n",
    "    ens_f1_scores.append(f1_score(labels_i, final_preds_i))\n",
    "\n",
    "    print(f\"Precision (Zone {i+1}): {precision_score(labels_i, final_preds_i):.2f}\")\n",
    "    print(f\"Recall (Zone {i+1}): {recall_score(labels_i, final_preds_i):.2f}\")\n",
    "    print(f\"F1-score (Zone {i+1}): {f1_score(labels_i, final_preds_i):.2f}\\n\")\n",
    "\n",
    "# Print overall ensemble results\n",
    "print(f\"Final Precision: {np.mean(ens_precision_scores):.2f} +/- {np.std(ens_precision_scores):.2f}\")\n",
    "print(f\"Final Recall: {np.mean(ens_recall_scores):.2f} +/- {np.std(ens_recall_scores):.2f}\")\n",
    "print(f\"Final F1-score: {np.mean(ens_f1_scores):.2f} +/- {np.std(ens_f1_scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131b6a2-56ae-4fc0-8e3f-83488d2fdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensemble approach with multiple spatial cross-validations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d079e-d6c1-4b10-9a4f-f488307c7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the unique zones and reverse their order\n",
    "zones = dataset['zone'].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    'vegetation', 'slope', 'profile_co', 'entropy', 'nodes',\n",
    "    'roads', 'mean_conne', 'min_connex', 'max_connex'\n",
    "]\n",
    "\n",
    "# Initialize lists to store final metrics across all cross-validations\n",
    "final_f1_scores = [[] for _ in range(len(zones))]\n",
    "final_precision_scores = [[] for _ in range(len(zones))]\n",
    "final_recall_scores = [[] for _ in range(len(zones))]\n",
    "final_kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "# Perform 10 rounds of cross-validation\n",
    "for n in range(10):\n",
    "\n",
    "    print(f\"----- Cross-Validation Round {n+1} -----\\n\")\n",
    "\n",
    "    # Initialize lists to store per-zone metrics for this round\n",
    "    f1_scores = [[] for _ in range(len(zones))]\n",
    "    precision_scores = [[] for _ in range(len(zones))]\n",
    "    recall_scores = [[] for _ in range(len(zones))]\n",
    "    kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "    # Store predictions for ensemble evaluation\n",
    "    preds = []\n",
    "\n",
    "    # Iterate over each zone for spatial cross-validation\n",
    "    for test_zone in zones:\n",
    "\n",
    "        # Split dataset into training and testing sets\n",
    "        train_dataset = dataset[dataset['zone'] != test_zone]\n",
    "        test_dataset = dataset[dataset['zone'] == test_zone]\n",
    "\n",
    "        X_train, y_train = train_dataset[feature_cols].values, train_dataset['label'].values\n",
    "        X_test, y_test = test_dataset[feature_cols].values, test_dataset['label'].values\n",
    "        test_ids = test_dataset['id'].values\n",
    "\n",
    "        # Separate test samples by class\n",
    "        class_0 = X_test[y_test == 0]\n",
    "        class_1 = X_test[y_test == 1]\n",
    "\n",
    "        ids_class_0 = test_ids[y_test == 0]\n",
    "        ids_class_1 = test_ids[y_test == 1]\n",
    "\n",
    "        # Balance the test set through downsampling\n",
    "        if len(class_0) > len(class_1):\n",
    "            X_class_0_downsampled, ids_class_0_downsampled = resample(\n",
    "                class_0, ids_class_0, replace=False, n_samples=len(class_1)\n",
    "            )\n",
    "            X_test_balanced = np.vstack([X_class_0_downsampled, class_1])\n",
    "            y_test_balanced = np.hstack([np.zeros(len(X_class_0_downsampled)), np.ones(len(class_1))])\n",
    "            ids_test_balanced = np.hstack([ids_class_0_downsampled, ids_class_1])\n",
    "        else:\n",
    "            X_class_1_downsampled, ids_class_1_downsampled = resample(\n",
    "                class_1, ids_class_1, replace=False, n_samples=len(class_0)\n",
    "            )\n",
    "            X_test_balanced = np.vstack([class_0, X_class_1_downsampled])\n",
    "            y_test_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(X_class_1_downsampled))])\n",
    "            ids_test_balanced = np.hstack([ids_class_0, ids_class_1_downsampled])\n",
    "\n",
    "        # Shuffle the test dataset\n",
    "        p = np.random.permutation(len(y_test_balanced))\n",
    "        X_test_balanced, y_test_balanced, ids_test_balanced = X_test_balanced[p], y_test_balanced[p], ids_test_balanced[p]\n",
    "\n",
    "        # Store test IDs alongside actual labels\n",
    "        ids_test_balanced = np.column_stack((ids_test_balanced, y_test_balanced))\n",
    "\n",
    "        # Train 100 models for the ensemble approach\n",
    "        for _ in tqdm(range(100), desc=f\"Zone {int(test_zone)}\"):\n",
    "\n",
    "            # Balance the training dataset\n",
    "            class_0 = X_train[y_train == 0]\n",
    "            class_1 = X_train[y_train == 1]\n",
    "\n",
    "            if len(class_0) > len(class_1):\n",
    "                class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "                X_train_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "                y_train_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "            else:\n",
    "                class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "                X_train_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "                y_train_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "\n",
    "            # Shuffle the training dataset\n",
    "            p = np.random.permutation(len(y_train_balanced))\n",
    "            X_train_balanced, y_train_balanced = X_train_balanced[p], y_train_balanced[p]\n",
    "\n",
    "            # Train the model\n",
    "            model = RandomForestClassifier(n_estimators=100)\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "            # Predict on the balanced test set\n",
    "            y_pred = model.predict(X_test_balanced)\n",
    "\n",
    "            # Store predictions for ensemble evaluation\n",
    "            ids_test_balanced = np.column_stack((ids_test_balanced, y_pred))\n",
    "\n",
    "            # Compute and store evaluation metrics\n",
    "            f1_scores[int(test_zone - 1)].append(f1_score(y_test_balanced, y_pred))\n",
    "            precision_scores[int(test_zone - 1)].append(precision_score(y_test_balanced, y_pred))\n",
    "            recall_scores[int(test_zone - 1)].append(recall_score(y_test_balanced, y_pred))\n",
    "            kappa_scores[int(test_zone - 1)].append(cohen_kappa_score(y_test_balanced, y_pred))\n",
    "\n",
    "        preds.append(ids_test_balanced)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Ensemble evaluation\n",
    "    ens_recall_scores = []\n",
    "    ens_precision_scores = []\n",
    "    ens_f1_scores = []\n",
    "    ens_kappa_scores = []\n",
    "\n",
    "    for i in zones:\n",
    "        i = int(i - 1)\n",
    "        ids_i = preds[i][:, 0]\n",
    "        labels_i = preds[i][:, 1]\n",
    "        preds_i = preds[i][:, 2:]\n",
    "\n",
    "        # Use majority voting for final ensemble prediction\n",
    "        final_preds_i = np.array([1 if np.mean(l) >= 0.5 else 0 for l in preds_i])\n",
    "\n",
    "        # Compute final ensemble metrics\n",
    "        ens_precision_scores.append(precision_score(labels_i, final_preds_i))\n",
    "        ens_recall_scores.append(recall_score(labels_i, final_preds_i))\n",
    "        ens_f1_scores.append(f1_score(labels_i, final_preds_i))\n",
    "        ens_kappa_scores.append(cohen_kappa_score(labels_i, final_preds_i))\n",
    "\n",
    "        final_precision_scores[i].append(precision_score(labels_i, final_preds_i))\n",
    "        final_recall_scores[i].append(recall_score(labels_i, final_preds_i))\n",
    "        final_f1_scores[i].append(f1_score(labels_i, final_preds_i))\n",
    "        final_kappa_scores[i].append(cohen_kappa_score(labels_i, final_preds_i))\n",
    "\n",
    "    # Print per-zone ensemble results\n",
    "    print(f\"Precision: {np.mean(ens_precision_scores):.2f} ± {np.std(ens_precision_scores):.2f}\")\n",
    "    print(f\"Recall: {np.mean(ens_recall_scores):.2f} ± {np.std(ens_recall_scores):.2f}\")\n",
    "    print(f\"F1-score: {np.mean(ens_f1_scores):.2f} ± {np.std(ens_f1_scores):.2f}\")\n",
    "    print(f\"Kappa: {np.mean(ens_kappa_scores):.2f} ± {np.std(ens_kappa_scores):.2f}\\n\")\n",
    "\n",
    "print(\"----- Summary -----\\n\")\n",
    "\n",
    "# Print final metrics for each zone\n",
    "for i in range(len(zones)):\n",
    "    print(f\"Zone {i+1} Precision: {np.mean(final_precision_scores[i]):.2f} ± {np.std(final_precision_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} Recall: {np.mean(final_recall_scores[i]):.2f} ± {np.std(final_recall_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} F1-score: {np.mean(final_f1_scores[i]):.2f} ± {np.std(final_f1_scores[i]):.2f}\")\n",
    "    print(f\"Zone {i+1} Kappa: {np.mean(final_kappa_scores[i]):.2f} ± {np.std(final_kappa_scores[i]):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ff8f1-b0fa-4416-aba5-b5e6a63fe272",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sensitivity analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e4424-4b93-4195-9c76-9cd1660ef42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Load the grid shapefile\n",
    "grid = gpd.read_file(\"/path/to/your/data/data.gpkg\")\n",
    "\n",
    "# Lists to store sensitivity results\n",
    "f1_scores_sensib = []\n",
    "precision_scores_sensib = []\n",
    "recall_scores_sensib = []\n",
    "kappa_scores_sensib = []\n",
    "\n",
    "# Loop over different threshold values\n",
    "for p in [i / 10 for i in range(1, 10)]:\n",
    "    # Define labels based on varying favela coverage thresholds\n",
    "    grid[\"label\"] = np.where(\n",
    "        (grid[\"vegetation\"] <= 0.95)\n",
    "        & (grid[\"ghsl\"] >= 0.5)\n",
    "        & (grid[\"osm\"] <= 0.5)\n",
    "        & (grid[\"favelas\"] > p),\n",
    "        1,\n",
    "        np.where(\n",
    "            (grid[\"vegetation\"] <= 0.95)\n",
    "            & (grid[\"ghsl\"] >= 0.5)\n",
    "            & (grid[\"osm\"] <= 0.5)\n",
    "            & (grid[\"favelas\"] == 0),\n",
    "            0,\n",
    "            np.nan,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset = grid[grid[\"label\"].notna()].copy()\n",
    "\n",
    "    # Load zones shapefile\n",
    "    zones = gpd.read_file(\"/path/to/your/data/zones.shp\")\n",
    "\n",
    "    # Assign each cell to a zone based on centroid location\n",
    "    dataset[\"centroid\"] = dataset.geometry.centroid\n",
    "    points_zones = gpd.sjoin(\n",
    "        dataset.set_geometry(\"centroid\"),\n",
    "        zones[[\"fid\", \"geometry\"]],\n",
    "        how=\"left\",\n",
    "        predicate=\"within\",\n",
    "    )\n",
    "    dataset[\"zone\"] = points_zones[\"fid\"]\n",
    "    dataset = dataset.drop(columns=[\"centroid\"])\n",
    "    dataset = dataset[dataset[\"zone\"].notna()]\n",
    "\n",
    "    zones = dataset[\"zone\"].unique().tolist()\n",
    "    zones.reverse()\n",
    "\n",
    "    # Feature columns\n",
    "    f_cols = [\n",
    "        \"vegetation\", \"slope\", \"profile_co\", \"entropy\",\n",
    "        \"nodes\", \"roads\", \"mean_conne\", \"min_connex\", \"max_connex\"\n",
    "    ]\n",
    "\n",
    "    # Initialize performance metric lists\n",
    "    f1_scores = [[] for _ in range(len(zones))]\n",
    "    precision_scores = [[] for _ in range(len(zones))]\n",
    "    recall_scores = [[] for _ in range(len(zones))]\n",
    "    kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    for _ in range(5):\n",
    "        folds = []\n",
    "\n",
    "        for zone_id in zones:\n",
    "            dataset_zone = dataset[dataset[\"zone\"] == zone_id]\n",
    "            X, y = dataset_zone[f_cols].values, dataset_zone[\"label\"].values\n",
    "\n",
    "            class_0 = X[y == 0]\n",
    "            class_1 = X[y == 1]\n",
    "\n",
    "            # Balance the dataset\n",
    "            if len(class_0) > len(class_1):\n",
    "                class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "                X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "                y_balanced = np.hstack([\n",
    "                    np.zeros(len(class_0_downsampled)),\n",
    "                    np.ones(len(class_1)),\n",
    "                ])\n",
    "            else:\n",
    "                class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "                X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "                y_balanced = np.hstack([\n",
    "                    np.zeros(len(class_0)),\n",
    "                    np.ones(len(class_1_downsampled)),\n",
    "                ])\n",
    "\n",
    "            # Shuffle dataset\n",
    "            perm_idx = np.random.permutation(len(y_balanced))\n",
    "            X_balanced, y_balanced = X_balanced[perm_idx], y_balanced[perm_idx]\n",
    "\n",
    "            folds.append([X_balanced, y_balanced])\n",
    "\n",
    "        # Cross-validation training and evaluation\n",
    "        for i in range(len(folds)):\n",
    "            X_test, y_test = folds[i]\n",
    "            X_train = np.vstack([fold[0] for j, fold in enumerate(folds) if j != i])\n",
    "            y_train = np.hstack([fold[1] for j, fold in enumerate(folds) if j != i])\n",
    "\n",
    "            model = RandomForestClassifier(random_state=None)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            precision_scores[i].append(precision_score(y_test, y_pred))\n",
    "            recall_scores[i].append(recall_score(y_test, y_pred))\n",
    "            f1_scores[i].append(f1_score(y_test, y_pred))\n",
    "            kappa_scores[i].append(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "    # Compute average metrics for current threshold\n",
    "    mean_precision = np.mean([np.mean(f) for f in precision_scores])\n",
    "    mean_recall = np.mean([np.mean(f) for f in recall_scores])\n",
    "    mean_f1 = np.mean([np.mean(f) for f in f1_scores])\n",
    "    mean_kappa = np.mean([np.mean(f) for f in kappa_scores])\n",
    "\n",
    "    print(f\"Threshold {p:.1f}\")\n",
    "    print(f\"Precision: {mean_precision:.2f}\")\n",
    "    print(f\"Recall: {mean_recall:.2f}\")\n",
    "    print(f\"F1-score: {mean_f1:.2f}\")\n",
    "    print(f\"Kappa: {mean_kappa:.2f}\\n\")\n",
    "\n",
    "    # Store results for sensitivity curve\n",
    "    precision_scores_sensib.append(mean_precision)\n",
    "    recall_scores_sensib.append(mean_recall)\n",
    "    f1_scores_sensib.append(mean_f1)\n",
    "    kappa_scores_sensib.append(mean_kappa)\n",
    "\n",
    "# --- Plot sensitivity analysis ---\n",
    "font_path = \"/usr/share/fonts/truetype/cmu/cmunrm.ttf\"\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "font_prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = font_prop.get_name()\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(10, 91, 10), f1_scores_sensib, marker=\"o\", linestyle=\"-\", label=\"F1-score\")\n",
    "plt.plot(range(10, 91, 10), kappa_scores_sensib, marker=\"o\", linestyle=\"-\", label=\"Kappa\")\n",
    "\n",
    "plt.xlabel(\"Favela Coverage Proportion (%)\", fontsize=12)\n",
    "plt.ylabel(\"Performance Metrics\", fontsize=12)\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sensitivity_analysis.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
