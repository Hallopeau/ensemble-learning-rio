{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac34512-8517-4119-bbf0-8291e1bc2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81036764-9c75-41ba-84a3-9f2e7999d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "class GridGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate a grid of polygons over a raster image.\n",
    "\n",
    "    Attributes:\n",
    "        image_path (str): Path to the raster image.\n",
    "        taille_carreau (float): Size of each grid cell in the same units as the raster's CRS.\n",
    "        output_grid_path (str): Path to save the generated grid shapefile.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_path, output_grid_path=None, taille_carreau=150):\n",
    "        \"\"\"\n",
    "        Initializes the GridGenerator with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            image_path (str): Path to the raster image.\n",
    "            output_grid_path (str, optional): Path to save the generated grid shapefile.\n",
    "            taille_carreau (float): Size of each grid cell in the same units as the raster's CRS.\n",
    "        \"\"\"\n",
    "        self.image_path = image_path\n",
    "        self.taille_carreau = taille_carreau\n",
    "        if output_grid_path is None:\n",
    "            output_grid_path = f\"{image_path.rsplit('.', 1)[0]}_grid.shp\"\n",
    "        self.output_grid_path = output_grid_path\n",
    "\n",
    "    def generate_grid(self):\n",
    "        \"\"\"\n",
    "        Generates a grid of polygons over the raster image and saves it to a shapefile.\n",
    "        \"\"\"\n",
    "        with rasterio.open(self.image_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "\n",
    "        xmin, ymin, xmax, ymax = bounds\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        cols = int(width // self.taille_carreau)\n",
    "        rows = int(height // self.taille_carreau)\n",
    "\n",
    "        polygons = []\n",
    "        for i in range(cols):\n",
    "            for j in range(rows):\n",
    "                x_left = xmin + i * self.taille_carreau\n",
    "                x_right = xmin + (i + 1) * self.taille_carreau\n",
    "                y_top = ymax - j * self.taille_carreau\n",
    "                y_bottom = ymax - (j + 1) * self.taille_carreau\n",
    "\n",
    "                polygon = Polygon([\n",
    "                    (x_left, y_top),\n",
    "                    (x_right, y_top),\n",
    "                    (x_right, y_bottom),\n",
    "                    (x_left, y_bottom)\n",
    "                ])\n",
    "                polygons.append(polygon)\n",
    "\n",
    "        grid_gdf = gpd.GeoDataFrame(geometry=polygons, crs=crs)\n",
    "        grid_gdf.to_file(self.output_grid_path)\n",
    "\n",
    "\n",
    "image_path = \"/path/to/your/image/S2.tif\"\n",
    "grid_generator = GridGenerator(image_path)\n",
    "grid_generator.generate_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943a7db-cbd4-4668-908c-064ed140074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entropy calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b76763-a70c-4b53-ae39-37ed709a5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "\n",
    "def normalize_band(band: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize a band between 0 and 1.\n",
    "    \"\"\"\n",
    "    return rescale_intensity(band, out_range=(0, 1))\n",
    "\n",
    "\n",
    "def compute_entropy_block(block: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute entropy for a 15x15 pixel block.\n",
    "    \"\"\"\n",
    "    hist = torch.histc(block, bins=256, min=0.0, max=1.0)\n",
    "    probs = hist / hist.sum()\n",
    "    probs = torch.clamp(probs, min=epsilon)\n",
    "    entropy = -torch.sum(probs * torch.log(probs))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# File paths\n",
    "sentinel2_path = \"/path/to/your/data/S2.tif\"\n",
    "entropy_output_path = \"/path/to/your/output/entropy.tif\"\n",
    "\n",
    "# Load Sentinel-2 image\n",
    "with rasterio.open(sentinel2_path) as src:\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        'height': src.height // 15,\n",
    "        'width': src.width // 15,\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'transform': src.transform * src.transform.scale(15, 15)\n",
    "    })\n",
    "\n",
    "    entropy_avg = np.zeros((meta['height'], meta['width']), dtype=np.float32)\n",
    "\n",
    "    for i in range(1, 13):\n",
    "        band = src.read(i)\n",
    "        band_normalized = normalize_band(band)\n",
    "        band_tensor = torch.tensor(band_normalized, dtype=torch.float32)\n",
    "\n",
    "        for y in range(0, band_tensor.size(0) - 15 + 1, 15):\n",
    "            for x in range(0, band_tensor.size(1) - 15 + 1, 15):\n",
    "                block = band_tensor[y:y+15, x:x+15]\n",
    "                entropy = compute_entropy_block(block)\n",
    "                entropy_avg[y // 15, x // 15] += entropy.item()\n",
    "\n",
    "    entropy_avg /= 12.0\n",
    "\n",
    "    with rasterio.open(entropy_output_path, 'w', **meta) as dst:\n",
    "        dst.write(entropy_avg, 1)\n",
    "\n",
    "print(f\"Entropy TIFF file generated: {entropy_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48bd3e-a581-479c-b777-45d4c08f35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEM feature calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2ee26-48ac-4da4-8bf8-970dbd390bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy.ndimage import sobel\n",
    "\n",
    "\n",
    "def calculate_slope(dem: np.ndarray, resolution: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the slope from the Digital Elevation Model (DEM).\n",
    "\n",
    "    Parameters:\n",
    "        dem (numpy.ndarray): 2D array representing the DEM.\n",
    "        resolution (float): Spatial resolution of the DEM (pixel size in meters).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2D array containing slope values in degrees.\n",
    "    \"\"\"\n",
    "    dx = sobel(dem, axis=1) / (8.0 * resolution)  # East-West gradient\n",
    "    dy = sobel(dem, axis=0) / (8.0 * resolution)  # North-South gradient\n",
    "\n",
    "    slope_rad = np.arctan(np.sqrt(dx**2 + dy**2))\n",
    "    slope_deg = np.degrees(slope_rad)\n",
    "\n",
    "    return slope_deg\n",
    "\n",
    "\n",
    "def calculate_profile_convexity(dem: np.ndarray, resolution: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the profile convexity from the Digital Elevation Model (DEM).\n",
    "\n",
    "    Parameters:\n",
    "        dem (numpy.ndarray): 2D array representing the DEM.\n",
    "        resolution (float): Spatial resolution of the DEM (pixel size in meters).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2D array containing profile convexity values.\n",
    "    \"\"\"\n",
    "    dzdx = sobel(dem, axis=1) / (8.0 * resolution)\n",
    "    dzdy = sobel(dem, axis=0) / (8.0 * resolution)\n",
    "\n",
    "    aspect = np.arctan2(dzdy, dzdx)\n",
    "\n",
    "    d2zdx2 = sobel(dzdx, axis=1) / (8.0 * resolution)\n",
    "    d2zdy2 = sobel(dzdy, axis=0) / (8.0 * resolution)\n",
    "\n",
    "    profile_convexity = d2zdx2 * np.cos(aspect) ** 2 + d2zdy2 * np.sin(aspect) ** 2\n",
    "\n",
    "    return profile_convexity\n",
    "\n",
    "\n",
    "dem_path = \"/path/to/your/data/cop_dem.tif\"\n",
    "slope_output_path = \"/path/to/your/output/slope_output.tif\"\n",
    "convexity_output_path = \"/path/to/your/output/profile_convexity_output.tif\"\n",
    "\n",
    "with rasterio.open(dem_path) as dem_dataset:\n",
    "    dem = dem_dataset.read(1)\n",
    "    resolution = dem_dataset.transform[0]\n",
    "\n",
    "    slope = calculate_slope(dem, resolution)\n",
    "    profile_convexity = calculate_profile_convexity(dem, resolution)\n",
    "\n",
    "    profile = dem_dataset.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1, nodata=None)\n",
    "\n",
    "    with rasterio.open(slope_output_path, \"w\", **profile) as slope_dataset:\n",
    "        slope_dataset.write(slope.astype(rasterio.float32), 1)\n",
    "\n",
    "    with rasterio.open(convexity_output_path, \"w\", **profile) as convexity_dataset:\n",
    "        convexity_dataset.write(profile_convexity.astype(rasterio.float32), 1)\n",
    "\n",
    "print(f\"Slope file saved as: {slope_output_path}\")\n",
    "print(f\"Profile convexity file saved as: {convexity_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb510e-829c-4230-9984-bd18ce5f51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OSM feature integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5a080-bbc1-4bf7-a85d-c0e6b74efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load the shapefile grid\n",
    "grid = gpd.read_file(\"/path/to/your/data/grid.gpkg\")\n",
    "print(f\"Grid loaded: {len(grid)} cells\")\n",
    "\n",
    "# Load OSM shapefiles for nodes and edges\n",
    "osm_nodes = gpd.read_file(\"/path/to/your/data/osm_nodes.shp\")\n",
    "osm_edges = gpd.read_file(\"/path/to/your/data/osm_edges.shp\")\n",
    "\n",
    "print(f\"OSM nodes loaded: {len(osm_nodes)}\")\n",
    "print(f\"OSM edges loaded: {len(osm_edges)}\")\n",
    "\n",
    "# Convert CRS of OSM data to match the grid\n",
    "osm_nodes = osm_nodes.to_crs(grid.crs)\n",
    "osm_edges = osm_edges.to_crs(grid.crs)\n",
    "\n",
    "# Add columns for statistics in the grid\n",
    "grid[\"nodes\"] = 0\n",
    "grid[\"roads\"] = 0.0\n",
    "grid[\"mean_connections\"] = 0.0\n",
    "grid[\"min_connections\"] = 0.0\n",
    "grid[\"max_connections\"] = 0.0\n",
    "\n",
    "# Compute statistics for each grid cell\n",
    "for idx, row in tqdm(grid.iterrows(), total=len(grid)):\n",
    "    geometry = row[\"geometry\"]\n",
    "\n",
    "    # Filter nodes inside the cell\n",
    "    nodes_in_cell = osm_nodes[osm_nodes.intersects(geometry)]\n",
    "    grid.at[idx, \"nodes\"] = len(nodes_in_cell)\n",
    "\n",
    "    # Filter roads inside the cell\n",
    "    roads_in_cell = osm_edges[osm_edges.intersects(geometry)]\n",
    "\n",
    "    # Compute total road length inside the cell\n",
    "    total_length = sum(\n",
    "        route.geometry.intersection(geometry).length for _, route in roads_in_cell.iterrows()\n",
    "    )\n",
    "    grid.at[idx, \"roads\"] = total_length\n",
    "\n",
    "    # Compute connection statistics\n",
    "    if len(nodes_in_cell) > 0:\n",
    "        connections = nodes_in_cell[\"street_cou\"].values  \n",
    "        grid.at[idx, \"mean_connections\"] = connections.mean()\n",
    "        grid.at[idx, \"min_connections\"] = connections.min()\n",
    "        grid.at[idx, \"max_connections\"] = connections.max()\n",
    "\n",
    "# Save updated grid\n",
    "grid.to_file(\"grid.shp\")\n",
    "print(\"Grid saved with road network statistics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7be1a3-c768-4472-a410-4128e67b6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raster feature integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20587716-53d3-428b-a47c-b5138d0faffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_cell_mean(geometry, affine, raster_tensor, device):\n",
    "    \"\"\"\n",
    "    Calculate the mean pixel value inside a grid cell.\n",
    "\n",
    "    Parameters:\n",
    "        geometry (shapely.geometry.Polygon): Grid cell geometry.\n",
    "        affine (Affine): Raster transformation matrix.\n",
    "        raster_tensor (torch.Tensor): Raster values on device.\n",
    "        device (torch.device): Device (CPU or GPU).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean pixel value within the cell.\n",
    "    \"\"\"\n",
    "    mask = geometry_mask(\n",
    "        [geometry], transform=affine, invert=True, out_shape=raster_tensor.shape\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.bool, device=device)\n",
    "    cell_pixels = raster_tensor[mask_tensor]\n",
    "\n",
    "    if cell_pixels.numel() > 0:\n",
    "        return torch.nanmean(cell_pixels).item()\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def save_grid(grid, index):\n",
    "    \"\"\"\n",
    "    Save the grid with computed entropy values as a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "        grid (GeoDataFrame): Grid data.\n",
    "        index (str): Suffix for output filename.\n",
    "    \"\"\"\n",
    "    filename = f\"grid_{index}.shp\"\n",
    "    print(f\"Saving: {filename}\")\n",
    "    grid.to_file(filename)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the shapefile grid\n",
    "grid = gpd.read_file(\"/path/to/your/data/grid.gpkg\")\n",
    "\n",
    "# Open the raster file\n",
    "with rasterio.open(\"/path/to/your/data/entropy.tif\") as src:\n",
    "    affine = src.transform\n",
    "    raster_data = src.read(1)\n",
    "    raster_nodata = src.nodata\n",
    "\n",
    "# Convert raster data to tensor and move to device\n",
    "raster_tensor = torch.tensor(raster_data, dtype=torch.float32, device=device)\n",
    "\n",
    "if raster_nodata is not None:\n",
    "    raster_tensor[raster_tensor == raster_nodata] = float(\"nan\")\n",
    "\n",
    "print(f\"Raster converted to tensor with shape {raster_tensor.shape}\")\n",
    "\n",
    "# Initialize new column\n",
    "grid[\"entropy\"] = np.nan\n",
    "\n",
    "print(\"Computing mean pixel values for each grid cell...\")\n",
    "\n",
    "for idx, row in tqdm(grid.iterrows(), total=len(grid)):\n",
    "    geometry = row[\"geometry\"]\n",
    "    mean_value = compute_cell_mean(geometry, affine, raster_tensor, device)\n",
    "    grid.at[idx, \"entropy\"] = mean_value\n",
    "\n",
    "save_grid(grid, \"final\")\n",
    "print(\"Grid saved with computed entropy values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054d674-abf8-4643-be16-ddedfa7d7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector feature integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dca89-13af-428a-afca-996930baeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_intersection_proportions(grid: gpd.GeoDataFrame, dataset: gpd.GeoDataFrame, label: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the proportion of each grid cell area intersecting with a dataset.\n",
    "\n",
    "    Parameters:\n",
    "        grid (GeoDataFrame): Grid containing cell geometries.\n",
    "        dataset (GeoDataFrame): Dataset to intersect.\n",
    "        label (str): Name of the column storing intersection proportions.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Aggregated intersection proportions for each grid cell.\n",
    "    \"\"\"\n",
    "    intersections = gpd.sjoin(grid, dataset, how=\"left\", predicate=\"intersects\").reset_index()\n",
    "\n",
    "    tqdm.pandas(desc=f\"Computing proportions for {label}\")\n",
    "    intersections[\"intersection_surface\"] = intersections.progress_apply(\n",
    "        lambda row: (\n",
    "            row[\"geometry\"].intersection(dataset.loc[row[\"index_right\"], \"geometry\"]).area\n",
    "            / row[\"cell_surface\"]\n",
    "            if pd.notnull(row[\"index_right\"])\n",
    "            else 0\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        intersections.groupby(\"index\")\n",
    "        .agg({\"intersection_surface\": \"sum\"})\n",
    "        .rename(columns={\"intersection_surface\": label})\n",
    "    )\n",
    "\n",
    "\n",
    "# Load shapefiles\n",
    "grid = gpd.read_file(\"/path/to/your/data/grid.shp\")\n",
    "vegetation = gpd.read_file(\"/path/to/your/data/vegetation.shp\")\n",
    "ghsl = gpd.read_file(\"/path/to/your/data/ghsl.shp\")\n",
    "favelas = gpd.read_file(\"/path/to/your/data/favelas.shp\")\n",
    "osm = gpd.read_file(\"/path/to/your/data/open_street_map.shp\")\n",
    "\n",
    "# Ensure CRS consistency\n",
    "if favelas.crs != grid.crs:\n",
    "    favelas = favelas.to_crs(grid.crs)\n",
    "\n",
    "# Compute surface area of each cell\n",
    "grid[\"cell_surface\"] = grid.geometry.area\n",
    "\n",
    "# Compute intersection proportions\n",
    "vegetation_agg = compute_intersection_proportions(grid, vegetation, \"vegetation\")\n",
    "ghsl_agg = compute_intersection_proportions(grid, ghsl, \"ghsl\")\n",
    "favelas_agg = compute_intersection_proportions(grid, favelas, \"favelas\")\n",
    "osm_agg = compute_intersection_proportions(grid, osm, \"osm\")\n",
    "\n",
    "# Merge results into grid\n",
    "grid = (\n",
    "    grid.reset_index()\n",
    "    .merge(vegetation_agg, on=\"index\", how=\"left\")\n",
    "    .merge(ghsl_agg, on=\"index\", how=\"left\")\n",
    "    .merge(favelas_agg, on=\"index\", how=\"left\")\n",
    "    .merge(osm_agg, on=\"index\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "for col in [\"vegetation\", \"ghsl\", \"favelas\", \"osm\"]:\n",
    "    grid[col] = grid[col].fillna(0)\n",
    "\n",
    "# Save final result\n",
    "grid.to_file(\"data.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d378d-81b0-46dd-b559-bca510c59d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba15de-c88b-4264-84c3-8f91cfa4cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load the shapefiles\n",
    "grid = gpd.read_file(\"/path/to/your/data/data.gpkg\")\n",
    "boundary = gpd.read_file(\"/path/to/your/data/city_boundary.shp\")\n",
    "\n",
    "# Ensure both datasets share the same CRS\n",
    "boundary = boundary.to_crs(grid.crs)\n",
    "\n",
    "# Add an ID column to the grid\n",
    "grid[\"id\"] = grid.index\n",
    "\n",
    "# Initialize tqdm for progress tracking\n",
    "tqdm.pandas()\n",
    "\n",
    "# Spatial join: keep only grid cells intersecting the boundary\n",
    "grid_filtered = gpd.sjoin(grid, boundary, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "# Drop extra columns from the spatial join\n",
    "grid_filtered = grid_filtered[grid.columns]\n",
    "\n",
    "# Save the filtered grid\n",
    "output_path = \"/path/to/your/output/data.gpkg\"\n",
    "grid_filtered.to_file(output_path, driver=\"GPKG\")\n",
    "\n",
    "print(f\"Remaining cells: {len(grid_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acacdde-80f9-46d8-92e3-500c1cad1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adc917-6c25-4659-98b0-85af2ba813d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load shapefile\n",
    "grid = gpd.read_file(\"/path/to/your/data/data.gpkg\")\n",
    "\n",
    "# Assign labels based on defined conditions\n",
    "grid[\"label\"] = np.where(\n",
    "    (grid[\"vegetation\"] <= 0.95)\n",
    "    & (grid[\"ghsl\"] >= 0.5)\n",
    "    & (grid[\"osm\"] <= 0.5)\n",
    "    & (grid[\"favelas\"] > 0.9),\n",
    "    1,\n",
    "    np.where(\n",
    "        (grid[\"vegetation\"] <= 0.95)\n",
    "        & (grid[\"ghsl\"] >= 0.5)\n",
    "        & (grid[\"osm\"] <= 0.5)\n",
    "        & (grid[\"favelas\"] == 0),\n",
    "        0,\n",
    "        np.nan,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Keep only labeled data\n",
    "dataset = grid[grid[\"label\"].notna()].copy()\n",
    "\n",
    "# Load zones shapefile\n",
    "zones = gpd.read_file(\"/path/to/your/data/zones.shp\")\n",
    "\n",
    "# Assign each grid cell to a zone\n",
    "dataset[\"centroid\"] = dataset.geometry.centroid\n",
    "points_zones = gpd.sjoin(\n",
    "    dataset.set_geometry(\"centroid\"),\n",
    "    zones[[\"fid\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "dataset[\"zone\"] = points_zones[\"fid\"]\n",
    "dataset = dataset.drop(columns=[\"centroid\"])\n",
    "dataset = dataset[dataset[\"zone\"].notna()]\n",
    "\n",
    "# Compute statistics per zone\n",
    "for label in [1, 0]:\n",
    "    print(f\"\\nStatistics for label {label}:\")\n",
    "    total = len(dataset[dataset[\"label\"] == label])\n",
    "    for i in dataset[\"zone\"].unique():\n",
    "        count = len(dataset[(dataset[\"zone\"] == i) & (dataset[\"label\"] == label)])\n",
    "        ratio = count / total if total > 0 else 0\n",
    "        print(f\"Zone {int(i)}: {count} ({ratio:.2f})\")\n",
    "\n",
    "# Print total counts of each label\n",
    "print(\"\\nTotal labeled samples:\")\n",
    "print(f\"Label 0: {len(dataset[dataset['label'] == 0])}\")\n",
    "print(f\"Label 1: {len(dataset[dataset['label'] == 1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
